{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message = \"Applied workaround for CuDNN issue\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, OneCycleLR, ExponentialLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Custom Imports\n",
    "from tests import test_utils\n",
    "from tests import loading_utils\n",
    "from residual_networks.ResKNet import ResKNet\n",
    "from residual_networks.DenseKNet import DenseKNet\n",
    "from residual_networks.RegKNet import RegKNet\n",
    "from residual_networks.ResKNeXt import ResKNeXt\n",
    "from residual_networks.VGGK import VGGK\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77c8d453d8d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPRODUCIBLE = True\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if REPRODUCIBLE:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "SEED = 10\n",
    "set_seed(SEED)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: tiny_imagenet, batch size: 256\n",
      "training images: 100000\n",
      "validation images: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset_list = {\"cifar_100\": [256, 100, \"small\", 32], \"cifar_10\": [256, 10, \"small\", 32], \"tiny_imagenet\": [256, 200, \"medium\", 64], \"imagenet_1k\": [32, 1000, \"large\", 224]}\n",
    "dataset = list(dataset_list.keys())[2]\n",
    "batch_size, num_classes, dataset_size, input_size = dataset_list.get(dataset)\n",
    "print(f\"dataset: {dataset}, batch size: {batch_size}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if dataset == \"cifar_100\":\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.CIFAR10),\n",
    "        # transforms.RandAugment(num_ops = 2, magnitude = 9),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root = \"./cifar_data\", train = True, download = False, transform = train_transform)\n",
    "    val_dataset = torchvision.datasets.CIFAR100(root = \"./cifar_data\", train = False, download = False, transform = val_transform)\n",
    "\n",
    "elif dataset == \"cifar_10\":\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.CIFAR10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root = \"./cifar_data\", train = True, download = False, transform = train_transform)\n",
    "    val_dataset = torchvision.datasets.CIFAR10(root = \"./cifar_data\", train = False, download = False, transform = val_transform)\n",
    "\n",
    "elif dataset == \"tiny_imagenet\":\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = ImageFolder(root = \"./tiny-imagenet-200/train\", transform = train_transform)\n",
    "    val_dataset = ImageFolder(root = \"./tiny-imagenet-200/val\", transform = val_transform)\n",
    "\n",
    "elif dataset == \"imagenet_1k\":\n",
    "    train_dir = \"imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "    val_dir = \"imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val\"\n",
    "    val_ann_dir = \"imagenet-object-localization-challenge/ILSVRC/Annotations/CLS-LOC/val\"\n",
    "    synset_to_class = loading_utils.generate_synset_to_class_mapping(train_dir)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(root = train_dir, transform = train_transform)\n",
    "    val_dataset = loading_utils.ImageNetValDataset(img_dir = val_dir, ann_dir = val_ann_dir, synset_to_class = synset_to_class, transform = val_transform)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset '{dataset}'. Please specify 'cifar_100', 'tiny_imagenet', or 'imagenet_1k'.\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 8, pin_memory = True, worker_init_fn = seed_worker, generator = g)\n",
    "test_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 8, pin_memory = True, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "print(f\"training images: {len(train_dataset)}\")\n",
    "print(f\"validation images: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResKNet(version = \"resnet18\", num_classes = num_classes, reduce_factor = [2, 2, 2, 2], dataset_size = dataset_size,\n",
    "                   mechanisms = [None, None, None, \"se\"], single_conv = True, fcl = \"resnet\").to(device)\n",
    "\n",
    "warmup_epochs = 0\n",
    "initial_lr = 0.1\n",
    "num_epochs = 350\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = initial_lr, weight_decay = 1e-3)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr = initial_lr, weight_decay = 5e-4)\n",
    "warmup_scheduler = LambdaLR(optimizer, lr_lambda = lambda epoch: test_utils.warmup_scheduler(epoch, warmup_epochs))\n",
    "# scheduler = ReduceLROnPlateau(optimizer, \"min\", patience = 5, factor = 0.5)\n",
    "# scheduler = ExponentialLR(optimizer, gamma = 0.95)\n",
    "# scheduler = test_utils.DecreasingCosineAnnealingWarmRestarts(optimizer, T_0 = 150, T_mult = 1, eta_min = 1e-5, decay_factor = 0.5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr = 0.1, steps_per_epoch = len(train_loader), epochs = num_epochs, pct_start = 0.2, div_factor = 10, final_div_factor = 1000)\n",
    "scaler = GradScaler()\n",
    "early_stopping = test_utils.EarlyStopping(patience = 350, min_delta = 0, path = \"cifar100.pt\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "best_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top5_correct = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scale_before = scaler.get_scale()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scale_before <= scaler.get_scale() and isinstance(scheduler, OneCycleLR):\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        top5_correct += torch.topk(outputs, 5, dim = 1)[1].eq(targets.view(-1, 1)).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100. * correct / total)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\\n\"\n",
    "          f\"Training Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Top-1 Accuracy: {100. * correct/total:.2f}%, \"\n",
    "          f\"Top-5 Accuracy: {100. * top5_correct/total:.2f}%, \"\n",
    "          f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "def validate():\n",
    "    global best_loss, best_epoch\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top5_correct = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            top5_correct += torch.topk(outputs, 5, dim = 1)[1].eq(targets.view(-1, 1)).sum().item()\n",
    "\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_targets, all_preds, average = \"macro\")\n",
    "    val_loss = running_loss / len(test_loader)\n",
    "    val_losses.append(running_loss / len(test_loader))\n",
    "    val_accuracies.append(100. * correct / total)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, \"\n",
    "          f\"Top-1 Accuracy: {100. * correct/total:.2f}%, \"\n",
    "          f\"Top-5 Accuracy: {100. * top5_correct/total:.2f}%\\n\"\n",
    "          f\"Best Val Loss: {best_loss:.4f} (Epoch {best_epoch}), F1 Score: {f1:.4f}, \"\n",
    "          f\"Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(val_loss)\n",
    "        elif isinstance(scheduler, OneCycleLR):\n",
    "            pass\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "    early_stopping(running_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train(epoch)\n",
    "    if validate():\n",
    "        break\n",
    "\n",
    "test_utils.profile_model(model, input_size, device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_accuracy = max(val_accuracies)\n",
    "best_epoch = val_accuracies.index(max_val_accuracy) + 1\n",
    "min_val_loss = val_losses[val_accuracies.index(max_val_accuracy)]\n",
    "print(f\"Highest Accuracy: {max_val_accuracy:.2f}% at Epoch {best_epoch}, Loss: {min_val_loss:.4f}\")\n",
    "print(', '.join(f\"{loss:.4f}\" for loss in val_losses))\n",
    "print(', '.join(f\"{accuracy:.2f}\" for accuracy in val_accuracies))\n",
    "\n",
    "window_size = 1\n",
    "smooth_train_losses = test_utils.moving_average(train_losses[:best_epoch], window_size)\n",
    "smooth_val_losses = test_utils.moving_average(val_losses[:best_epoch], window_size)\n",
    "smooth_train_accuracies = test_utils.moving_average(train_accuracies[:best_epoch], window_size)\n",
    "smooth_val_accuracies = test_utils.moving_average(val_accuracies[:best_epoch], window_size)\n",
    "x_smooth = np.arange(window_size, best_epoch + 1)\n",
    "\n",
    "# plt.plot(np.arange(1, best_epoch + 1), train_losses[:best_epoch], label = \"Training Loss\")\n",
    "# plt.plot(np.arange(1, best_epoch + 1), val_losses[:best_epoch], label = \"Validation Loss\")\n",
    "plt.plot(x_smooth, smooth_train_losses, label = \"Training Loss\")\n",
    "plt.plot(x_smooth, smooth_val_losses, label = \"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(np.arange(1, best_epoch + 1), train_accuracies[:best_epoch], label = \"Training Accuracy\")\n",
    "# plt.plot(np.arange(1, best_epoch + 1), val_accuracies[:best_epoch], label = \"Validation Accuracy\")\n",
    "plt.plot(x_smooth, smooth_train_accuracies, label = \"Training Accuracy\")\n",
    "plt.plot(x_smooth, smooth_val_accuracies, label = \"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
