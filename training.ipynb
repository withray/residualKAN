{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message = \"Applied workaround for CuDNN issue\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, OneCycleLR, ExponentialLR, CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Custom Imports\n",
    "from tests import test_utils\n",
    "from tests import loading_utils\n",
    "from residual_networks.RKAN_ResNet import RKAN_ResNet\n",
    "from residual_networks.RKAN_DenseNet import RKAN_DenseNet\n",
    "from residual_networks.RKAN_RegNet import RKAN_RegNet\n",
    "from residual_networks.RKAN_ResNeXt import RKAN_ResNeXt\n",
    "from residual_networks.RKAN_WideResNet import RKAN_WideResNet\n",
    "from residual_networks.RKAN_VGG import RKAN_VGG\n",
    "from residual_networks.RKAN_ConvNeXt import RKAN_ConvNeXt\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79e87f0ce890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPRODUCIBLE = True\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if REPRODUCIBLE:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "SEED = 10\n",
    "set_seed(SEED)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: imagenet_1k\n",
      "training images: 1281167\n",
      "validation images: 50000\n",
      "Image batch shape: torch.Size([256, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataset_list = {\"cifar_100\": [256, 100, \"small\", 32, \"full\"], \"cifar_10\": [256, 10, \"small\", 32, \"full\"], \"svhn\": [256, 10, \"small\", 32, \"full\"],\n",
    "                \"tiny_imagenet\": [256, 200, \"medium\", 64, \"full\"], \"food_101\": [256, 101, \"large\", 128, \"full\"], \"imagenet_1k\": [256, 1000, \"large\", 224, \"transfer\"]}\n",
    "dataset = list(dataset_list.keys())[5]\n",
    "batch_size, num_classes, dataset_size, input_size, train_status = dataset_list.get(dataset, [None, None, None, None, None])\n",
    "print(f\"dataset: {dataset}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_upscale = True\n",
    "upscale_check = image_upscale and dataset_size == \"large\"\n",
    "\n",
    "if dataset in [\"cifar_100\", \"cifar_10\", \"svhn\"]:\n",
    "    if upscale_check:\n",
    "        input_size = 128\n",
    "    if dataset == \"cifar_100\":\n",
    "        normalize_mean, normalize_std = (0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)\n",
    "        augment_policy = transforms.AutoAugmentPolicy.CIFAR10\n",
    "    elif dataset == \"cifar_10\":\n",
    "        normalize_mean, normalize_std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "        augment_policy = transforms.AutoAugmentPolicy.CIFAR10\n",
    "    else:\n",
    "        normalize_mean, normalize_std = (0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970)\n",
    "        augment_policy = transforms.AutoAugmentPolicy.SVHN\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size, interpolation = transforms.InterpolationMode.BICUBIC) if upscale_check else transforms.RandomCrop(input_size, padding = 4),\n",
    "        transforms.RandomHorizontalFlip() if dataset != \"svhn\" else transforms.Lambda(lambda x: x),\n",
    "        transforms.AutoAugment(policy = augment_policy),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std)\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size, interpolation = transforms.InterpolationMode.BICUBIC) if upscale_check else transforms.Lambda(lambda x: x),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std)\n",
    "    ])\n",
    "\n",
    "    if dataset == \"cifar_100\":\n",
    "        train_dataset = torchvision.datasets.CIFAR100(root = \"./cifar_data\", train = True, download = False, transform = train_transform)\n",
    "        val_dataset = torchvision.datasets.CIFAR100(root = \"./cifar_data\", train = False, download = False, transform = val_transform)\n",
    "    elif dataset == \"cifar_10\":\n",
    "        train_dataset = torchvision.datasets.CIFAR10(root = \"./cifar_data\", train = True, download = False, transform = train_transform)\n",
    "        val_dataset = torchvision.datasets.CIFAR10(root = \"./cifar_data\", train = False, download = False, transform = val_transform)\n",
    "    else:\n",
    "        train_dataset = torchvision.datasets.SVHN(root = \"./svhn_data\", split = \"train\", download = False, transform = train_transform)\n",
    "        val_dataset = torchvision.datasets.SVHN(root = \"./svhn_data\", split = \"test\", download = False, transform = val_transform)\n",
    "\n",
    "elif dataset == \"tiny_imagenet\":\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(input_size, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = ImageFolder(root = \"./tiny-imagenet-200/train\", transform = train_transform)\n",
    "    val_dataset = ImageFolder(root = \"./tiny-imagenet-200/val\", transform = val_transform)\n",
    "\n",
    "elif dataset == \"food_101\":\n",
    "    image_dir = \"food-101/images\"\n",
    "    train_txt = os.path.join(\"food-101/meta\", \"train.txt\")\n",
    "    test_txt = os.path.join(\"food-101/meta\", \"test.txt\")\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(int(input_size * 1.25)),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = loading_utils.Food101Dataset(root_dir = image_dir, txt_file = train_txt, transform = train_transform)\n",
    "    val_dataset = loading_utils.Food101Dataset(root_dir = image_dir, txt_file = test_txt, transform = val_transform)\n",
    "\n",
    "elif dataset == \"imagenet_1k\":\n",
    "    train_dir = \"imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "    val_dir = \"imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val\"\n",
    "    val_ann_dir = \"imagenet-object-localization-challenge/ILSVRC/Annotations/CLS-LOC/val\"\n",
    "    synset_to_class = loading_utils.generate_synset_to_class_mapping(train_dir)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy = transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(root = train_dir, transform = train_transform)\n",
    "    val_dataset = loading_utils.ImageNetValDataset(img_dir = val_dir, ann_dir = val_ann_dir, synset_to_class = synset_to_class, transform = val_transform)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset '{dataset}'. Please specify 'cifar_100', 'cifar_10', 'svhn', 'tiny_imagenet', or 'imagenet_1k'.\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 8, pin_memory = True, worker_init_fn = seed_worker, generator = g)\n",
    "test_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 8, pin_memory = True, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "print(f\"training images: {len(train_dataset)}\")\n",
    "print(f\"validation images: {len(val_dataset)}\")\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"resnet18\": {\"class\": RKAN_ResNet, \"reduce_factor\": lambda r: r, \"single_conv\": False},\n",
    "    \"resnet34\": {\"class\": RKAN_ResNet, \"reduce_factor\": lambda r: r, \"single_conv\": False},\n",
    "    \"resnet50\": {\"class\": RKAN_ResNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"resnet101\": {\"class\": RKAN_ResNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"resnet152\": {\"class\": RKAN_ResNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"densenet121\": {\"class\": RKAN_DenseNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"densenet169\": {\"class\": RKAN_DenseNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"densenet201\": {\"class\": RKAN_DenseNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"resnext50_32x4d\": {\"class\": RKAN_ResNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"resnext101_32x8d\": {\"class\": RKAN_ResNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"wide_resnet50_2\": {\"class\": RKAN_WideResNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"wide_resnet101_2\": {\"class\": RKAN_WideResNet, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"convnext_tiny\": {\"class\": RKAN_ConvNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"convnext_small\": {\"class\": RKAN_ConvNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"convnext_base\": {\"class\": RKAN_ConvNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"convnext_large\": {\"class\": RKAN_ConvNeXt, \"reduce_factor\": lambda r: r, \"single_conv\": True},\n",
    "    \"regnet_y_400mf\": {\"class\": RKAN_RegNet, \"reduce_factor\": lambda r: r[-1], \"single_conv\": False},\n",
    "    \"regnet_y_800mf\": {\"class\": RKAN_RegNet, \"reduce_factor\": lambda r: r[-1], \"single_conv\": False},\n",
    "    \"regnet_y_1_6gf\": {\"class\": RKAN_RegNet, \"reduce_factor\": lambda r: r[-1], \"single_conv\": True},\n",
    "    \"regnet_y_3_2gf\": {\"class\": RKAN_RegNet, \"reduce_factor\": lambda r: r[-1], \"single_conv\": True},\n",
    "    \"vgg11_bn\": {\"class\": RKAN_VGG, \"reduce_factor\": lambda r: r[-1], \"single_conv\": False},\n",
    "    \"vgg13_bn\": {\"class\": RKAN_VGG, \"reduce_factor\": lambda r: r[-1], \"single_conv\": False},\n",
    "    \"vgg16_bn\": {\"class\": RKAN_VGG, \"reduce_factor\": lambda r: r[-1], \"single_conv\": True},\n",
    "    \"vgg19_bn\": {\"class\": RKAN_VGG, \"reduce_factor\": lambda r: r[-1], \"single_conv\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"regnet_y_800mf\"\n",
    "reduce_factor = [1, 1, 1, 1]\n",
    "mechanisms = [None, None, None, \"addition\"]\n",
    "pretrained = True if train_status == \"transfer\" else False\n",
    "model_config = model_configs.get(model_name)\n",
    "if model_config is None:\n",
    "    raise ValueError(f\"Unknown model name: '{model_name}'.\")\n",
    "model = model_config[\"class\"](version = model_name, num_classes = num_classes, reduce_factor = model_config[\"reduce_factor\"](reduce_factor),\n",
    "                              dataset_size = dataset_size, pretrained = pretrained, mechanisms = mechanisms, single_conv = model_config[\"single_conv\"]).to(device)\n",
    "\n",
    "warmup_epochs = 0\n",
    "use_cutmix = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if train_status == \"full\":\n",
    "    initial_lr = 0.1\n",
    "    num_epochs = 200\n",
    "    optimizer = optim.SGD(model.parameters(), lr = initial_lr, weight_decay = 1e-3)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, \"min\", patience = 5, factor = 0.5)\n",
    "    # scheduler = ExponentialLR(optimizer, gamma = 0.95)\n",
    "    # scheduler = test_utils.DecreasingCosineAnnealingWarmRestarts(optimizer, T_0 = 150, T_mult = 1, eta_min = 1e-5, decay_factor = 0.5)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr = 0.1, steps_per_epoch = len(train_loader), epochs = num_epochs, pct_start = 0.2, div_factor = 10, final_div_factor = 500)\n",
    "elif train_status == \"transfer\":\n",
    "    use_cutmix = False\n",
    "    initial_lr = 0.001\n",
    "    num_epochs = 30\n",
    "    optimizer = optim.AdamW(model.parameters(), lr = initial_lr, weight_decay = 1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max = num_epochs, eta_min = 1e-5)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown train_status: '{train_status}'.\")\n",
    "    \n",
    "warmup_scheduler = LambdaLR(optimizer, lr_lambda = lambda epoch: test_utils.warmup_scheduler(epoch, warmup_epochs))\n",
    "scaler = GradScaler()\n",
    "early_stopping = test_utils.EarlyStopping(patience = num_epochs, min_delta = 0, path = \"best.pt\")\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "best_loss, best_epoch = float(\"inf\"), -1\n",
    "if hasattr(model, \"log_norms\") and model.log_norms:\n",
    "    train_base_norms, train_residual_norms, train_combined_norms = [], [], []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top5_correct = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if use_cutmix and np.random.rand() < 0.5:\n",
    "            inputs, targets_a, targets_b, lam = test_utils.cutmix_data(inputs, targets)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "        else:\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scale_before = scaler.get_scale()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scale_before <= scaler.get_scale() and isinstance(scheduler, OneCycleLR):\n",
    "            scheduler.step()\n",
    "            \n",
    "        if hasattr(model, \"log_norms\") and model.log_norms:\n",
    "            train_base_norms.extend(model.base_norms)\n",
    "            train_residual_norms.extend(model.residual_norms)\n",
    "            train_combined_norms.extend(model.combined_norms)\n",
    "            model.reset_norms()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        top5_correct += torch.topk(outputs, 5, dim = 1)[1].eq(targets.view(-1, 1)).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100. * correct / total)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\\n\"\n",
    "          f\"Training Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Top-1 Accuracy: {100. * correct/total:.2f}%, \"\n",
    "          f\"Top-5 Accuracy: {100. * top5_correct/total:.2f}%, \"\n",
    "          f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "def validate():\n",
    "    global best_loss, best_epoch\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = top5_correct = total = 0\n",
    "    all_targets, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            top5_correct += torch.topk(outputs, 5, dim = 1)[1].eq(targets.view(-1, 1)).sum().item()\n",
    "\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_targets, all_preds, average = \"macro\")\n",
    "    val_loss = running_loss / len(test_loader)\n",
    "    val_losses.append(running_loss / len(test_loader))\n",
    "    val_accuracies.append(100. * correct / total)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, \"\n",
    "          f\"Top-1 Accuracy: {100. * correct/total:.2f}%, \"\n",
    "          f\"Top-5 Accuracy: {100. * top5_correct/total:.2f}%\\n\"\n",
    "          f\"Best Val Loss: {best_loss:.4f} (Epoch {best_epoch}), F1 Score: {f1:.4f}, \"\n",
    "          f\"Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(val_loss)\n",
    "        elif isinstance(scheduler, OneCycleLR):\n",
    "            pass\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "    early_stopping(running_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping...\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train(epoch)\n",
    "    if validate():\n",
    "        break\n",
    "\n",
    "test_utils.profile_model(model, input_size, device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_accuracy = max(val_accuracies)\n",
    "best_epoch = val_accuracies.index(max_val_accuracy) + 1\n",
    "min_val_loss = val_losses[val_accuracies.index(max_val_accuracy)]\n",
    "print(f\"Highest Accuracy: {max_val_accuracy:.2f}% at Epoch {best_epoch}, Loss: {min_val_loss:.4f}\")\n",
    "print(', '.join(f\"{loss:.4f}\" for loss in val_losses))\n",
    "print(', '.join(f\"{accuracy:.2f}\" for accuracy in val_accuracies))\n",
    "if hasattr(model, \"log_norms\") and model.log_norms:\n",
    "    print(', '.join(f\"{norms:.4f}\" for norms in train_base_norms))\n",
    "    print(', '.join(f\"{norms:.4f}\" for norms in train_residual_norms))\n",
    "    print(', '.join(f\"{norms:.4f}\" for norms in train_combined_norms))\n",
    "\n",
    "window_size = 1\n",
    "smooth_train_losses = test_utils.moving_average(train_losses[:best_epoch], window_size)\n",
    "smooth_val_losses = test_utils.moving_average(val_losses[:best_epoch], window_size)\n",
    "smooth_train_accuracies = test_utils.moving_average(train_accuracies[:best_epoch], window_size)\n",
    "smooth_val_accuracies = test_utils.moving_average(val_accuracies[:best_epoch], window_size)\n",
    "x_smooth = np.arange(window_size, best_epoch + 1)\n",
    "\n",
    "plt.plot(x_smooth, smooth_train_losses, label = \"Training Loss\")\n",
    "plt.plot(x_smooth, smooth_val_losses, label = \"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x_smooth, smooth_train_accuracies, label = \"Training Accuracy\")\n",
    "plt.plot(x_smooth, smooth_val_accuracies, label = \"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
